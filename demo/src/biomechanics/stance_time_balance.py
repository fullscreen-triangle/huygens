#!/usr/bin/env python3
"""
Stance Time Balance Oscillatory Analysis

Validates oscillatory theories using REAL left/right balance data from track running.
Stance time balance represents oscillatory coupling between left and right legs during running.

This script applies the Universal Biological Oscillatory Framework to analyze:
1. Left/right oscillatory coupling symmetry and asymmetry patterns
2. Bilateral oscillatory phase relationships and synchronization
3. Balance oscillation stability and adaptive responses
4. Multi-scale coupling with cadence, speed, and terrain
5. Oscillatory phase coherence between limbs
6. Validation of bilateral biological oscillator coupling theory

REVOLUTIONARY VALIDATION: First framework to analyze bilateral oscillatory coupling in real biomechanics!
"""

import sys
import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import signal, stats, fft
from scipy.optimize import curve_fit
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

class StanceTimeBalanceAnalyzer:
    """
    Analyzes stance time balance using bilateral oscillatory coupling theory
    """
    
    def __init__(self, data_file="../../experimental-data/circuit/annotated_track_series.json", 
                 results_dir="biomechanics_results/stance_time_balance"):
        self.data_file = Path(data_file)
        self.results_dir = Path(results_dir)
        self.results_dir.mkdir(parents=True, exist_ok=True)
        
        # Theoretical predictions from bilateral oscillatory framework
        self.theoretical_predictions = {
            'optimal_balance_range': (48, 52),  # % - near perfect 50/50 balance
            'balance_stability_threshold': 2.0,  # Standard deviation < 2% for stable balance
            'asymmetry_tolerance': 5.0,  # Maximum acceptable asymmetry in %
            'bilateral_coupling_strength': 0.7,  # Expected anti-phase coupling strength
            'phase_coherence_threshold': 0.6,  # Minimum coherence for synchronized oscillation
            'adaptation_responsiveness': 0.3,  # Balance adaptation coefficient
            'oscillatory_phase_difference': np.pi,  # 180¬∞ phase difference for optimal gait
            'balance_entropy_threshold': 0.8,  # Information entropy for balance complexity
        }
        
        # Load and validate data
        self.data = None
        self.balance_time_series = None
        self.validation_results = {}
        
        print("‚öñÔ∏è‚ö° STANCE TIME BALANCE ANALYZER ‚ö°‚öñÔ∏è")
        print("=" * 60)
        print("Analyzing bilateral oscillatory coupling - left/right coordination!")
        print("=" * 60)
    
    def load_track_data(self):
        """Load and preprocess the annotated track series data"""
        print("\nüìÇ Loading Track Data")
        print("-" * 40)
        
        try:
            with open(self.data_file, 'r') as f:
                raw_data = json.load(f)
            
            # Convert to DataFrame
            self.data = pd.DataFrame(raw_data)
            
            # Clean and validate stance time balance data
            # Remove invalid values (0 or extreme values)
            self.data = self.data[
                (self.data['stance_time_balance'] > 0) & 
                (self.data['stance_time_balance'] < 100)
            ]
            self.data = self.data.reset_index(drop=True)
            
            # Create time series
            self.balance_time_series = self.data['stance_time_balance'].values
            
            print(f"‚úÖ Loaded {len(self.data)} data points")
            print(f"üìä Balance range: {self.balance_time_series.min():.1f} - {self.balance_time_series.max():.1f} %")
            print(f"‚è±Ô∏è  Time span: {self.data['time'].max() - self.data['time'].min():.1f} seconds")
            print(f"‚öñÔ∏è  Mean Balance: {np.mean(self.balance_time_series):.2f} ¬± {np.std(self.balance_time_series):.2f} %")
            
            return True
            
        except Exception as e:
            print(f"‚ùå Error loading data: {str(e)}")
            return False
    
    def analyze_bilateral_balance_stability(self):
        """
        Analyze bilateral balance stability and oscillatory symmetry
        Tests: Bilateral Oscillatory Coupling Theory
        """
        print("\nüî¨ EXPERIMENT 1: Bilateral Balance Stability Analysis")
        print("-" * 55)
        
        if self.balance_time_series is None:
            print("‚ùå No data available")
            return {}
        
        results = {}
        balance = self.balance_time_series
        
        # Basic balance characteristics
        mean_balance = np.mean(balance)
        std_balance = np.std(balance)
        cv_balance = std_balance / mean_balance if mean_balance > 0 else 0
        balance_range = np.max(balance) - np.min(balance)
        
        # Calculate asymmetry metrics
        perfect_balance = 50.0  # Perfect 50/50 balance
        mean_asymmetry = abs(mean_balance - perfect_balance)
        asymmetry_variance = np.var(balance - perfect_balance)
        
        results['balance_characteristics'] = {
            'mean_balance': mean_balance,
            'std_balance': std_balance,
            'cv_balance': cv_balance,
            'balance_range': balance_range,
            'mean_asymmetry': mean_asymmetry,
            'asymmetry_variance': asymmetry_variance,
            'balance_stability': std_balance < self.theoretical_predictions['balance_stability_threshold']
        }
        
        print(f"Mean Balance: {mean_balance:.2f} ¬± {std_balance:.2f} %")
        print(f"Mean Asymmetry: {mean_asymmetry:.2f} %")
        print(f"Balance Stability: {'‚úÖ STABLE' if results['balance_characteristics']['balance_stability'] else '‚ö†Ô∏è  UNSTABLE'}")
        
        # Optimal balance range validation
        optimal_range = self.theoretical_predictions['optimal_balance_range']
        in_optimal_range = np.sum((balance >= optimal_range[0]) & (balance <= optimal_range[1]))
        optimal_percentage = in_optimal_range / len(balance) * 100
        
        results['balance_range_validation'] = {
            'optimal_range_adherence': optimal_percentage,
            'range_violations': len(balance) - in_optimal_range,
            'theoretical_bounds': optimal_range,
            'optimal_balance_maintained': optimal_percentage > 70  # 70% in optimal range
        }
        
        print(f"Optimal Balance Range Adherence: {optimal_percentage:.1f}%")
        print(f"Optimal Balance: {'‚úÖ MAINTAINED' if results['balance_range_validation']['optimal_balance_maintained'] else '‚ö†Ô∏è  COMPROMISED'}")
        
        # Bilateral oscillatory symmetry analysis
        if len(balance) > 20:
            # Calculate left/right phase information
            # Balance > 50% = right leg dominant, < 50% = left leg dominant
            right_dominant_phases = balance > 50.0
            left_dominant_phases = balance < 50.0
            balanced_phases = np.abs(balance - 50.0) < 1.0  # Within 1% of perfect balance
            
            phase_distribution = {
                'right_dominant_percentage': np.sum(right_dominant_phases) / len(balance) * 100,
                'left_dominant_percentage': np.sum(left_dominant_phases) / len(balance) * 100,
                'balanced_percentage': np.sum(balanced_phases) / len(balance) * 100
            }
            
            results['phase_distribution'] = phase_distribution
            
            print(f"Right Dominant: {phase_distribution['right_dominant_percentage']:.1f}%")
            print(f"Left Dominant: {phase_distribution['left_dominant_percentage']:.1f}%")
            print(f"Balanced: {phase_distribution['balanced_percentage']:.1f}%")
            
            # Calculate phase transitions and oscillatory patterns
            phase_changes = np.diff(balance)
            transition_frequency = np.sum(np.abs(phase_changes) > 2.0) / len(phase_changes)  # Significant transitions
            
            results['oscillatory_transitions'] = {
                'mean_phase_change': np.mean(np.abs(phase_changes)),
                'phase_change_variance': np.var(phase_changes),
                'transition_frequency': transition_frequency,
                'oscillatory_activity': transition_frequency * np.std(phase_changes)
            }
            
            print(f"Mean Phase Change: {np.mean(np.abs(phase_changes)):.3f} %")
            print(f"Transition Frequency: {transition_frequency:.3f}")
        
        # Balance entropy analysis (complexity measure)
        if len(balance) > 10:
            # Discretize balance values for entropy calculation
            balance_bins = np.linspace(np.min(balance), np.max(balance), 10)
            balance_hist, _ = np.histogram(balance, bins=balance_bins)
            
            # Calculate information entropy
            balance_probabilities = balance_hist / np.sum(balance_hist)
            balance_probabilities = balance_probabilities[balance_probabilities > 0]  # Remove zeros
            
            balance_entropy = -np.sum(balance_probabilities * np.log2(balance_probabilities))
            max_entropy = np.log2(len(balance_bins) - 1)  # Maximum possible entropy
            normalized_entropy = balance_entropy / max_entropy
            
            results['balance_complexity'] = {
                'balance_entropy': balance_entropy,
                'normalized_entropy': normalized_entropy,
                'max_entropy': max_entropy,
                'balance_complexity_adequate': normalized_entropy >= self.theoretical_predictions['balance_entropy_threshold']
            }
            
            print(f"Balance Entropy: {balance_entropy:.3f} (normalized: {normalized_entropy:.3f})")
            print(f"Balance Complexity: {'‚úÖ ADEQUATE' if results['balance_complexity']['balance_complexity_adequate'] else '‚ö†Ô∏è  LIMITED'}")
        
        # Validate theoretical predictions
        predictions_validated = {}
        
        # Test balance stability
        predictions_validated['balance_stability'] = results['balance_characteristics']['balance_stability']
        
        # Test asymmetry tolerance
        asymmetry_threshold = self.theoretical_predictions['asymmetry_tolerance']
        predictions_validated['asymmetry_tolerance'] = mean_asymmetry <= asymmetry_threshold
        
        # Test optimal range maintenance
        predictions_validated['optimal_range'] = results['balance_range_validation']['optimal_balance_maintained']
        
        # Test balance complexity
        if 'balance_complexity' in results:
            predictions_validated['balance_complexity'] = results['balance_complexity']['balance_complexity_adequate']
        
        results['theoretical_validation'] = predictions_validated
        validation_success = sum(predictions_validated.values()) >= 3  # At least 3/4 validations
        results['validation_success'] = validation_success
        
        print(f"üéØ Theoretical Validation: {'‚úÖ SUCCESS' if validation_success else '‚ùå FAILED'}")
        
        return results
    
    def analyze_bilateral_phase_coupling(self):
        """
        Analyze bilateral phase coupling and synchronization
        Tests: Multi-limb Oscillatory Coupling Theory
        """
        print("\nüî¨ EXPERIMENT 2: Bilateral Phase Coupling Analysis")
        print("-" * 52)
        
        if self.data is None:
            print("‚ùå No data available")
            return {}
        
        # Extract relevant data for coupling analysis
        balance = self.data['stance_time_balance'].values
        cadence = self.data['cadence'].values
        time_data = self.data['time'].values
        
        # Remove invalid data
        valid_indices = (balance > 0) & (balance < 100) & (cadence > 0)
        balance_clean = balance[valid_indices]
        cadence_clean = cadence[valid_indices]
        time_clean = time_data[valid_indices]
        
        if len(balance_clean) < 20:
            print("‚ùå Insufficient valid data")
            return {}
        
        results = {}
        
        # Phase relationship analysis
        # Convert balance percentage to phase angle
        # 50% = 0¬∞, >50% = positive phase, <50% = negative phase
        balance_centered = balance_clean - 50.0  # Center around 0
        phase_angles = (balance_centered / 50.0) * np.pi/2  # Map to ¬±œÄ/2
        
        results['phase_characteristics'] = {
            'mean_phase_angle': np.mean(phase_angles),
            'phase_angle_std': np.std(phase_angles),
            'phase_angle_range': np.max(phase_angles) - np.min(phase_angles),
            'phase_coherence': 1.0 / (1.0 + np.var(phase_angles))  # Inverse of variance
        }
        
        print(f"Mean Phase Angle: {np.mean(phase_angles):.3f} rad")
        print(f"Phase Coherence: {results['phase_characteristics']['phase_coherence']:.3f}")
        
        # Bilateral coupling with cadence
        # Analyze how balance oscillations couple with step frequency
        balance_cadence_correlation = np.corrcoef(balance_clean, cadence_clean)[0, 1]
        
        results['cadence_coupling'] = {
            'correlation_coefficient': balance_cadence_correlation,
            'coupling_strength': abs(balance_cadence_correlation),
            'significant_coupling': abs(balance_cadence_correlation) > 0.3
        }
        
        print(f"Balance-Cadence Coupling: {balance_cadence_correlation:.3f}")
        print(f"Significant Coupling: {'‚úÖ YES' if results['cadence_coupling']['significant_coupling'] else '‚ùå NO'}")
        
        # Cross-correlation analysis for phase relationships
        if len(balance_clean) > 50:
            # Calculate autocorrelation of balance to find oscillatory period
            balance_autocorr = np.correlate(balance_centered, balance_centered, mode='full')
            balance_autocorr = balance_autocorr[balance_autocorr.size // 2:]
            balance_autocorr = balance_autocorr / balance_autocorr[0]  # Normalize
            
            # Find first significant minimum (oscillatory period)
            significant_lags = np.where(balance_autocorr[1:20] < 0.1)[0]  # Look for correlation < 0.1
            
            if len(significant_lags) > 0:
                oscillatory_period = significant_lags[0] + 1
                
                results['oscillatory_period'] = {
                    'period_samples': oscillatory_period,
                    'period_coherence': balance_autocorr[oscillatory_period] if oscillatory_period < len(balance_autocorr) else 0,
                    'oscillation_detected': True
                }
                
                print(f"Oscillatory Period: {oscillatory_period} samples")
                print(f"Period Coherence: {results['oscillatory_period']['period_coherence']:.3f}")
            else:
                results['oscillatory_period'] = {'oscillation_detected': False}
                print("No clear oscillatory period detected")
        
        # Frequency domain analysis of bilateral coupling
        if len(balance_clean) > 100:
            # Power spectral density of balance oscillations
            frequencies, psd_balance = signal.periodogram(balance_centered, fs=1.0)
            
            # Coherence analysis between balance and cadence
            coherence_freqs, coherence = signal.coherence(balance_centered, cadence_clean, fs=1.0,
                                                        nperseg=min(64, len(balance_clean)//4))
            
            # Find peak coherence
            peak_coherence_idx = np.argmax(coherence[1:]) + 1  # Skip DC
            peak_coherence = coherence[peak_coherence_idx]
            peak_frequency = coherence_freqs[peak_coherence_idx]
            
            results['frequency_coupling'] = {
                'peak_coherence': peak_coherence,
                'peak_frequency': peak_frequency,
                'mean_coherence': np.mean(coherence[1:]),
                'strong_frequency_coupling': peak_coherence > self.theoretical_predictions['phase_coherence_threshold']
            }
            
            print(f"Peak Coherence: {peak_coherence:.3f} at {peak_frequency:.4f} Hz")
            print(f"Strong Frequency Coupling: {'‚úÖ YES' if results['frequency_coupling']['strong_frequency_coupling'] else '‚ùå NO'}")
        
        # Phase-amplitude coupling analysis
        if len(balance_clean) > 50:
            # Calculate phase-amplitude coupling between balance variations and cadence
            # This tests if amplitude of balance oscillations depends on phase of cadence
            
            # Extract phase of cadence using Hilbert transform
            try:
                cadence_analytic = signal.hilbert(cadence_clean - np.mean(cadence_clean))
                cadence_phase = np.angle(cadence_analytic)
                balance_amplitude = np.abs(balance_centered)
                
                # Calculate phase-amplitude coupling using mutual information approximation
                # Bin phases and amplitudes for analysis
                phase_bins = np.linspace(-np.pi, np.pi, 8)
                amp_bins = np.linspace(0, np.max(balance_amplitude), 8)
                
                phase_indices = np.digitize(cadence_phase, phase_bins)
                amp_indices = np.digitize(balance_amplitude, amp_bins)
                
                # Calculate phase-amplitude coupling strength
                pac_strength = 0.0
                n_valid_bins = 0
                
                for phase_bin in range(1, len(phase_bins)):
                    phase_mask = phase_indices == phase_bin
                    if np.sum(phase_mask) > 5:  # Sufficient data in bin
                        phase_amplitudes = balance_amplitude[phase_mask]
                        mean_amp_in_phase = np.mean(phase_amplitudes)
                        pac_strength += mean_amp_in_phase
                        n_valid_bins += 1
                
                if n_valid_bins > 0:
                    pac_strength = pac_strength / n_valid_bins
                    pac_normalized = pac_strength / np.mean(balance_amplitude)
                    
                    results['phase_amplitude_coupling'] = {
                        'pac_strength': pac_strength,
                        'pac_normalized': pac_normalized,
                        'significant_pac': pac_normalized > 1.2  # 20% above mean
                    }
                    
                    print(f"Phase-Amplitude Coupling: {pac_normalized:.3f}")
                    print(f"Significant PAC: {'‚úÖ YES' if results['phase_amplitude_coupling']['significant_pac'] else '‚ùå NO'}")
                
            except Exception as e:
                print(f"Phase-amplitude coupling analysis failed: {str(e)}")
        
        # Bilateral symmetry over time
        if len(balance_clean) > 20:
            # Calculate rolling symmetry metrics
            window_size = min(20, len(balance_clean) // 4)
            rolling_asymmetry = []
            
            for i in range(window_size, len(balance_clean) - window_size):
                window_balance = balance_clean[i-window_size:i+window_size]
                window_asymmetry = abs(np.mean(window_balance) - 50.0)
                rolling_asymmetry.append(window_asymmetry)
            
            if rolling_asymmetry:
                results['temporal_symmetry'] = {
                    'mean_rolling_asymmetry': np.mean(rolling_asymmetry),
                    'asymmetry_variance': np.var(rolling_asymmetry),
                    'asymmetry_stability': 1.0 / (1.0 + np.var(rolling_asymmetry)),
                    'consistent_symmetry': np.std(rolling_asymmetry) < 2.0
                }
                
                print(f"Mean Rolling Asymmetry: {np.mean(rolling_asymmetry):.2f} %")
                print(f"Consistent Symmetry: {'‚úÖ YES' if results['temporal_symmetry']['consistent_symmetry'] else '‚ùå NO'}")
        
        # Validate theoretical predictions
        predictions_validated = {}
        
        # Test phase coherence threshold
        if 'phase_characteristics' in results:
            coherence_threshold = self.theoretical_predictions['phase_coherence_threshold']
            predictions_validated['phase_coherence'] = results['phase_characteristics']['phase_coherence'] >= coherence_threshold
        
        # Test bilateral coupling strength
        if 'cadence_coupling' in results:
            predictions_validated['bilateral_coupling'] = results['cadence_coupling']['significant_coupling']
        
        # Test frequency coupling
        if 'frequency_coupling' in results:
            predictions_validated['frequency_coupling'] = results['frequency_coupling']['strong_frequency_coupling']
        
        # Test temporal symmetry consistency
        if 'temporal_symmetry' in results:
            predictions_validated['temporal_consistency'] = results['temporal_symmetry']['consistent_symmetry']
        
        # Test oscillatory period detection
        if 'oscillatory_period' in results:
            predictions_validated['oscillatory_period'] = results['oscillatory_period']['oscillation_detected']
        
        results['theoretical_validation'] = predictions_validated
        validation_success = sum(predictions_validated.values()) >= len(predictions_validated) // 2
        results['validation_success'] = validation_success
        
        print(f"üéØ Theoretical Validation: {'‚úÖ SUCCESS' if validation_success else '‚ùå FAILED'}")
        
        return results
    
    def analyze_terrain_balance_adaptation(self):
        """
        Analyze balance adaptation to different terrain segments
        Tests: Environmental Coupling in Bilateral Systems
        """
        print("\nüî¨ EXPERIMENT 3: Terrain Balance Adaptation Analysis")
        print("-" * 52)
        
        if self.data is None:
            print("‚ùå No data available")
            return {}
        
        # Group by track segments
        segment_data = self.data.groupby('segments')
        
        if len(segment_data) < 2:
            print("‚ùå Insufficient segment variety")
            return {}
        
        results = {}
        segment_analysis = {}
        
        print(f"Analyzing {len(segment_data)} different track segments:")
        
        for segment_name, segment_df in segment_data:
            if len(segment_df) < 5:  # Skip segments with too few points
                continue
                
            balance_segment = segment_df['stance_time_balance'].values
            valid_balance = (balance_segment > 0) & (balance_segment < 100)
            
            if np.sum(valid_balance) < 3:
                continue
                
            balance_clean = balance_segment[valid_balance]
            
            # Calculate segment-specific balance metrics
            segment_stats = {
                'n_points': len(balance_clean),
                'mean_balance': np.mean(balance_clean),
                'std_balance': np.std(balance_clean),
                'mean_asymmetry': abs(np.mean(balance_clean) - 50.0),
                'balance_range': np.max(balance_clean) - np.min(balance_clean),
                'balance_stability': np.std(balance_clean)
            }
            
            # Calculate adaptation-specific metrics
            segment_stats['adaptation_index'] = segment_stats['std_balance'] * segment_stats['mean_asymmetry']
            segment_stats['balance_efficiency'] = 1.0 / (1.0 + segment_stats['mean_asymmetry'])
            segment_stats['oscillatory_activity'] = np.var(np.diff(balance_clean)) if len(balance_clean) > 1 else 0
            
            segment_analysis[segment_name] = segment_stats
            
            print(f"  {segment_name}: {segment_stats['mean_balance']:.1f} ¬± {segment_stats['std_balance']:.1f} %")
            print(f"    Asymmetry: {segment_stats['mean_asymmetry']:.1f}%, Efficiency: {segment_stats['balance_efficiency']:.3f}")
        
        results['segment_analysis'] = segment_analysis
        
        # Cross-segment adaptation analysis
        if len(segment_analysis) >= 2:
            segment_names = list(segment_analysis.keys())
            
            # Extract metrics for comparison
            mean_balances = [segment_analysis[seg]['mean_balance'] for seg in segment_names]
            mean_asymmetries = [segment_analysis[seg]['mean_asymmetry'] for seg in segment_names]
            balance_stabilities = [segment_analysis[seg]['balance_stability'] for seg in segment_names]
            balance_efficiencies = [segment_analysis[seg]['balance_efficiency'] for seg in segment_names]
            
            # Calculate adaptation metrics
            balance_adaptation_range = np.max(mean_balances) - np.min(mean_balances)
            asymmetry_adaptation_range = np.max(mean_asymmetries) - np.min(mean_asymmetries)
            stability_adaptation_range = np.max(balance_stabilities) - np.min(balance_stabilities)
            
            results['adaptation_analysis'] = {
                'balance_adaptation_range': balance_adaptation_range,
                'asymmetry_adaptation_range': asymmetry_adaptation_range,
                'stability_adaptation_range': stability_adaptation_range,
                'mean_balance_efficiency': np.mean(balance_efficiencies),
                'adaptation_consistency': 1.0 - (np.std(mean_asymmetries) / np.mean(mean_asymmetries)) if np.mean(mean_asymmetries) > 0 else 1.0,
                'segment_count': len(segment_names)
            }
            
            print(f"Balance Adaptation Range: {balance_adaptation_range:.1f} %")
            print(f"Asymmetry Adaptation Range: {asymmetry_adaptation_range:.1f} %")
            print(f"Adaptation Consistency: {results['adaptation_analysis']['adaptation_consistency']:.3f}")
            
            # Statistical analysis of segment differences
            segment_balances = []
            segment_asymmetries = []
            
            for segment_name in segment_names:
                segment_df = self.data[self.data['segments'] == segment_name]
                valid_data = segment_df[
                    (segment_df['stance_time_balance'] > 0) & 
                    (segment_df['stance_time_balance'] < 100)
                ]
                
                if len(valid_data) >= 3:
                    balance_values = valid_data['stance_time_balance'].values
                    asymmetry_values = np.abs(balance_values - 50.0)
                    
                    segment_balances.append(balance_values)
                    segment_asymmetries.append(asymmetry_values)
            
            if len(segment_balances) >= 2:
                # ANOVA tests for significant differences
                try:
                    # Test balance differences
                    f_stat_balance, p_value_balance = stats.f_oneway(*segment_balances)
                    
                    # Test asymmetry differences
                    f_stat_asymmetry, p_value_asymmetry = stats.f_oneway(*segment_asymmetries)
                    
                    results['statistical_analysis'] = {
                        'balance_f_stat': f_stat_balance,
                        'balance_p_value': p_value_balance,
                        'asymmetry_f_stat': f_stat_asymmetry,
                        'asymmetry_p_value': p_value_asymmetry,
                        'significant_balance_adaptation': p_value_balance < 0.05,
                        'significant_asymmetry_adaptation': p_value_asymmetry < 0.05
                    }
                    
                    print(f"Balance ANOVA: F={f_stat_balance:.2f}, p={p_value_balance:.4f}")
                    print(f"Asymmetry ANOVA: F={f_stat_asymmetry:.2f}, p={p_value_asymmetry:.4f}")
                    print(f"Significant Adaptation: {'‚úÖ YES' if p_value_balance < 0.05 or p_value_asymmetry < 0.05 else '‚ùå NO'}")
                    
                except Exception as e:
                    print(f"Statistical analysis failed: {str(e)}")
        
        # Side-specific adaptation analysis
        if 'side' in self.data.columns:
            side_balance_analysis = {}
            
            for side in ['left', 'right']:
                side_data = self.data[self.data['side'] == side]
                valid_side_data = side_data[
                    (side_data['stance_time_balance'] > 0) & 
                    (side_data['stance_time_balance'] < 100)
                ]
                
                if len(valid_side_data) >= 10:
                    side_balance = valid_side_data['stance_time_balance'].values
                    
                    side_balance_analysis[side] = {
                        'mean_balance': np.mean(side_balance),
                        'std_balance': np.std(side_balance),
                        'mean_asymmetry': abs(np.mean(side_balance) - 50.0),
                        'n_points': len(side_balance)
                    }
            
            if len(side_balance_analysis) == 2:
                results['side_analysis'] = side_balance_analysis
                
                # Compare left vs right balance patterns
                left_balance = side_balance_analysis['left']['mean_balance']
                right_balance = side_balance_analysis['right']['mean_balance']
                
                lateral_bias = left_balance - right_balance
                results['lateral_analysis'] = {
                    'lateral_bias': lateral_bias,
                    'lateral_bias_magnitude': abs(lateral_bias),
                    'balanced_laterality': abs(lateral_bias) < 2.0  # Within 2% difference
                }
                
                print(f"Lateral Bias: {lateral_bias:.2f} % ({'Left' if lateral_bias > 0 else 'Right'} dominant)")
                print(f"Balanced Laterality: {'‚úÖ YES' if results['lateral_analysis']['balanced_laterality'] else '‚ùå NO'}")
        
        # Validate theoretical predictions
        predictions_validated = {}
        
        # Test adaptation responsiveness (should show some adaptation but not excessive)
        if 'adaptation_analysis' in results:
            reasonable_adaptation = (
                results['adaptation_analysis']['balance_adaptation_range'] < 10.0 and  # < 10% balance range
                results['adaptation_analysis']['asymmetry_adaptation_range'] < 8.0  # < 8% asymmetry range
            )
            predictions_validated['reasonable_adaptation'] = reasonable_adaptation
            
            # Test adaptation consistency
            consistency_threshold = 0.7
            predictions_validated['adaptation_consistency'] = results['adaptation_analysis']['adaptation_consistency'] >= consistency_threshold
            
            # Test mean balance efficiency
            efficiency_threshold = 0.8
            predictions_validated['balance_efficiency'] = results['adaptation_analysis']['mean_balance_efficiency'] >= efficiency_threshold
        
        # Test for significant but controlled adaptation
        if 'statistical_analysis' in results:
            adaptive_response = (results['statistical_analysis']['significant_balance_adaptation'] or 
                               results['statistical_analysis']['significant_asymmetry_adaptation'])
            predictions_validated['adaptive_response'] = adaptive_response
        
        # Test lateral balance
        if 'lateral_analysis' in results:
            predictions_validated['balanced_laterality'] = results['lateral_analysis']['balanced_laterality']
        
        results['theoretical_validation'] = predictions_validated
        validation_success = sum(predictions_validated.values()) >= len(predictions_validated) // 2
        results['validation_success'] = validation_success
        
        print(f"üéØ Theoretical Validation: {'‚úÖ SUCCESS' if validation_success else '‚ùå FAILED'}")
        
        return results
    
    def create_comprehensive_visualizations(self, results):
        """Generate comprehensive visualizations of stance time balance analysis"""
        print("\nüé® Creating Comprehensive Visualizations...")
        
        if self.data is None:
            print("‚ùå No data for visualization")
            return
        
        # Create comprehensive dashboard
        fig = plt.figure(figsize=(20, 16))
        
        # 1. Balance time series
        ax1 = plt.subplot(3, 4, 1)
        time = self.data['time'].values
        balance = self.data['stance_time_balance'].values
        
        plt.plot(time, balance, 'b-', alpha=0.7, linewidth=1)
        plt.axhline(y=50, color='r', linestyle='--', alpha=0.8, label='Perfect Balance (50%)')
        plt.axhline(y=np.mean(balance), color='g', linestyle='--', alpha=0.8, label=f'Mean: {np.mean(balance):.1f}%')
        
        # Add optimal range
        optimal_range = self.theoretical_predictions['optimal_balance_range']
        plt.axhspan(optimal_range[0], optimal_range[1], alpha=0.2, color='green', label='Optimal Range')
        
        plt.xlabel('Time (s)')
        plt.ylabel('Stance Time Balance (%)')
        plt.title('Balance Time Series')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # 2. Balance distribution
        ax2 = plt.subplot(3, 4, 2)
        plt.hist(balance, bins=20, alpha=0.7, color='blue', density=True)
        plt.axvline(x=50, color='red', linestyle='--', label='Perfect Balance')
        plt.axvline(x=np.mean(balance), color='green', linestyle='--', label=f'Mean: {np.mean(balance):.1f}%')
        plt.axvline(x=np.mean(balance) + np.std(balance), color='orange', linestyle='--', alpha=0.7)
        plt.axvline(x=np.mean(balance) - np.std(balance), color='orange', linestyle='--', alpha=0.7, 
                   label=f'¬±1œÉ: {np.std(balance):.1f}%')
        
        plt.xlabel('Stance Time Balance (%)')
        plt.ylabel('Density')
        plt.title('Balance Distribution')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # 3. Asymmetry over time
        ax3 = plt.subplot(3, 4, 3)
        asymmetry = np.abs(balance - 50.0)
        plt.plot(time, asymmetry, 'r-', alpha=0.7, linewidth=1)
        plt.axhline(y=np.mean(asymmetry), color='b', linestyle='--', alpha=0.8, label=f'Mean: {np.mean(asymmetry):.1f}%')
        plt.axhline(y=self.theoretical_predictions['asymmetry_tolerance'], color='orange', 
                   linestyle='--', alpha=0.8, label=f'Tolerance: {self.theoretical_predictions["asymmetry_tolerance"]:.1f}%')
        
        plt.xlabel('Time (s)')
        plt.ylabel('Asymmetry (%)')
        plt.title('Balance Asymmetry Over Time')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # 4. Balance vs Cadence coupling
        ax4 = plt.subplot(3, 4, 4)
        valid_data = self.data[(self.data['cadence'] > 0) & 
                              (self.data['stance_time_balance'] > 0) & 
                              (self.data['stance_time_balance'] < 100)]
        
        if len(valid_data) > 10:
            cadence_valid = valid_data['cadence'].values
            balance_valid = valid_data['stance_time_balance'].values
            
            scatter = plt.scatter(cadence_valid, balance_valid, alpha=0.6, 
                                c=valid_data['speed'].values, cmap='viridis', s=20)
            
            # Add trend line
            z = np.polyfit(cadence_valid, balance_valid, 1)
            p = np.poly1d(z)
            plt.plot(cadence_valid, p(cadence_valid), 'r--', alpha=0.8, linewidth=2)
            
            # Calculate correlation
            corr = np.corrcoef(cadence_valid, balance_valid)[0, 1]
            plt.text(0.05, 0.95, f'r = {corr:.3f}', transform=ax4.transAxes,
                    bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8))
            
            plt.colorbar(scatter, label='Speed (m/s)')
            plt.xlabel('Cadence (steps/min)')
            plt.ylabel('Balance (%)')
            plt.title('Balance-Cadence Coupling')
            plt.grid(True, alpha=0.3)
        
        # 5. Power spectral density of balance oscillations
        ax5 = plt.subplot(3, 4, 5)
        balance_centered = balance - 50.0
        if len(balance_centered) > 10:
            frequencies, psd = signal.periodogram(balance_centered, fs=1.0)
            plt.semilogy(frequencies[1:], psd[1:], 'b-', alpha=0.8)
            
            # Highlight dominant frequency
            dominant_idx = np.argmax(psd[1:]) + 1
            plt.scatter(frequencies[dominant_idx], psd[dominant_idx], color='red', s=100, zorder=5,
                       label=f'Peak: {frequencies[dominant_idx]:.4f} Hz')
            
            plt.xlabel('Frequency (Hz)')
            plt.ylabel('Power Spectral Density')
            plt.title('Balance Oscillation Spectrum')
            plt.legend()
            plt.grid(True, alpha=0.3)
        
        # 6. Segment-wise balance analysis
        ax6 = plt.subplot(3, 4, 6)
        segment_data = self.data.groupby('segments')
        
        segment_means = []
        segment_names = []
        segment_stds = []
        segment_asymmetries = []
        
        for segment_name, segment_df in segment_data:
            valid_segment = (segment_df['stance_time_balance'] > 0) & (segment_df['stance_time_balance'] < 100)
            if np.sum(valid_segment) >= 5:
                segment_balance = segment_df[valid_segment]['stance_time_balance'].values
                segment_means.append(np.mean(segment_balance))
                segment_stds.append(np.std(segment_balance))
                segment_asymmetries.append(abs(np.mean(segment_balance) - 50.0))
                segment_names.append(segment_name)
        
        if segment_means:
            x_pos = np.arange(len(segment_names))
            bars = plt.bar(x_pos, segment_means, yerr=segment_stds, alpha=0.7, capsize=5)
            
            # Color bars by asymmetry level
            if segment_asymmetries:
                colors = plt.cm.RdYlGn_r([asym/max(segment_asymmetries) for asym in segment_asymmetries])
                for bar, color in zip(bars, colors):
                    bar.set_color(color)
            
            plt.axhline(y=50, color='red', linestyle='--', alpha=0.7, label='Perfect Balance')
            plt.xticks(x_pos, segment_names, rotation=45)
            plt.ylabel('Balance (%)')
            plt.title('Segment Balance Analysis')
            plt.legend()
            plt.grid(True, alpha=0.3)
        
        # 7. Balance vs Speed relationship
        ax7 = plt.subplot(3, 4, 7)
        valid_speed_data = self.data[(self.data['speed'] > 0) & 
                                    (self.data['stance_time_balance'] > 0) & 
                                    (self.data['stance_time_balance'] < 100)]
        
        if len(valid_speed_data) > 10:
            speed_valid = valid_speed_data['speed'].values
            balance_valid = valid_speed_data['stance_time_balance'].values
            
            plt.scatter(speed_valid, balance_valid, alpha=0.6, 
                       c=valid_speed_data['time'].values, cmap='plasma', s=20)
            
            # Add trend line
            z = np.polyfit(speed_valid, balance_valid, 1)
            p = np.poly1d(z)
            plt.plot(speed_valid, p(speed_valid), 'r--', alpha=0.8, linewidth=2)
            
            plt.colorbar(label='Time (s)')
            plt.xlabel('Speed (m/s)')
            plt.ylabel('Balance (%)')
            plt.title('Speed-Balance Relationship')
            plt.grid(True, alpha=0.3)
        
        # 8. Phase space visualization
        ax8 = plt.subplot(3, 4, 8)
        if len(balance) > 20:
            # Create phase space plot: balance vs balance derivative
            balance_derivative = np.gradient(balance, time)
            
            scatter = plt.scatter(balance, balance_derivative, alpha=0.6, 
                                c=time, cmap='viridis', s=20)
            
            plt.axvline(x=50, color='red', linestyle='--', alpha=0.7, label='Perfect Balance')
            plt.axhline(y=0, color='red', linestyle='--', alpha=0.7, label='No Change')
            
            plt.colorbar(scatter, label='Time (s)')
            plt.xlabel('Balance (%)')
            plt.ylabel('Balance Change Rate (%/s)')
            plt.title('Balance Phase Space')
            plt.legend()
            plt.grid(True, alpha=0.3)
        
        # 9. Autocorrelation analysis
        ax9 = plt.subplot(3, 4, 9)
        if len(balance_centered) > 20:
            autocorr = np.correlate(balance_centered, balance_centered, mode='full')
            autocorr = autocorr[autocorr.size // 2:]
            autocorr = autocorr / autocorr[0]  # Normalize
            
            lags = np.arange(len(autocorr))
            plt.plot(lags[:min(50, len(lags))], autocorr[:min(50, len(autocorr))], 'b-', alpha=0.8)
            plt.axhline(y=0, color='k', linestyle='-', alpha=0.3)
            plt.axhline(y=0.5, color='r', linestyle='--', alpha=0.7, label='50% correlation')
            
            plt.xlabel('Lag')
            plt.ylabel('Autocorrelation')
            plt.title('Balance Autocorrelation')
            plt.legend()
            plt.grid(True, alpha=0.3)
        
        # 10. Side-specific analysis (if available)
        ax10 = plt.subplot(3, 4, 10)
        if 'side' in self.data.columns:
            side_data = []
            side_labels = []
            
            for side in ['left', 'right']:
                side_subset = self.data[
                    (self.data['side'] == side) & 
                    (self.data['stance_time_balance'] > 0) & 
                    (self.data['stance_time_balance'] < 100)
                ]
                
                if len(side_subset) >= 10:
                    side_data.append(side_subset['stance_time_balance'].values)
                    side_labels.append(side.capitalize())
            
            if side_data:
                plt.boxplot(side_data, labels=side_labels)
                plt.axhline(y=50, color='red', linestyle='--', alpha=0.7, label='Perfect Balance')
                plt.ylabel('Balance (%)')
                plt.title('Left vs Right Side Balance')
                plt.legend()
                plt.grid(True, alpha=0.3)
        
        # 11. Rolling statistics
        ax11 = plt.subplot(3, 4, 11)
        if len(balance) > 50:
            window_size = max(20, len(balance) // 10)
            rolling_mean = pd.Series(balance).rolling(window=window_size, center=True).mean()
            rolling_std = pd.Series(balance).rolling(window=window_size, center=True).std()
            
            plt.plot(time, rolling_mean, 'b-', alpha=0.8, label='Rolling Mean')
            plt.fill_between(time, rolling_mean - rolling_std, rolling_mean + rolling_std, 
                           alpha=0.3, color='blue', label='¬±1œÉ')
            plt.axhline(y=50, color='red', linestyle='--', alpha=0.7, label='Perfect Balance')
            
            plt.xlabel('Time (s)')
            plt.ylabel('Balance (%)')
            plt.title('Rolling Balance Statistics')
            plt.legend()
            plt.grid(True, alpha=0.3)
        
        # 12. Validation summary
        ax12 = plt.subplot(3, 4, 12)
        
        # Collect validation results
        validation_categories = []
        validation_scores = []
        
        for analysis_name, analysis_results in results.items():
            if isinstance(analysis_results, dict) and 'theoretical_validation' in analysis_results:
                theoretical_val = analysis_results['theoretical_validation']
                if isinstance(theoretical_val, dict):
                    for pred_name, pred_result in theoretical_val.items():
                        validation_categories.append(f"{analysis_name[:8]}_{pred_name[:8]}")
                        validation_scores.append(1 if pred_result else 0)
        
        if validation_categories:
            colors = ['green' if score else 'red' for score in validation_scores]
            bars = plt.barh(range(len(validation_categories)), validation_scores, color=colors, alpha=0.7)
            
            plt.yticks(range(len(validation_categories)), validation_categories)
            plt.xlabel('Validation Success')
            plt.title('Theoretical Validation Summary')
            plt.xlim(0, 1.2)
            
            # Add success/failure labels
            for i, (bar, score) in enumerate(zip(bars, validation_scores)):
                label = '‚úÖ' if score else '‚ùå'
                plt.text(0.6, bar.get_y() + bar.get_height()/2, label, 
                        ha='center', va='center', fontsize=12)
        
        plt.tight_layout()
        
        # Save visualization
        output_path = self.results_dir / 'stance_time_balance_analysis.png'
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"  üìä Comprehensive dashboard saved: {output_path}")
        
        # Create interactive visualization
        self._create_interactive_visualization(results)
    
    def _create_interactive_visualization(self, results):
        """Create interactive Plotly visualization"""
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=('Balance Time Series', 'Balance-Cadence Coupling', 
                          'Asymmetry Analysis', 'Segment Analysis'),
            specs=[[{"secondary_y": True}, {}],
                   [{}, {}]]
        )
        
        # Balance time series with asymmetry
        fig.add_trace(
            go.Scatter(x=self.data['time'], y=self.data['stance_time_balance'], 
                      name='Balance', line=dict(color='blue')),
            row=1, col=1
        )
        
        asymmetry = np.abs(self.data['stance_time_balance'] - 50.0)
        fig.add_trace(
            go.Scatter(x=self.data['time'], y=asymmetry, 
                      name='Asymmetry', line=dict(color='red')),
            row=1, col=1, secondary_y=True
        )
        
        # Balance vs Cadence
        valid_data = self.data[(self.data['cadence'] > 0) & 
                              (self.data['stance_time_balance'] > 0) & 
                              (self.data['stance_time_balance'] < 100)]
        
        if len(valid_data) > 10:
            fig.add_trace(
                go.Scatter(x=valid_data['cadence'], y=valid_data['stance_time_balance'],
                          mode='markers', name='Balance-Cadence',
                          marker=dict(color=valid_data['speed'], colorscale='viridis')),
                row=1, col=2
            )
        
        # Asymmetry over time
        fig.add_trace(
            go.Scatter(x=self.data['time'], y=asymmetry,
                      name='Asymmetry', line=dict(color='red')),
            row=2, col=1
        )
        
        # Segment analysis
        segment_data = self.data.groupby('segments')
        segment_means = []
        segment_names = []
        
        for segment_name, segment_df in segment_data:
            valid_segment = (segment_df['stance_time_balance'] > 0) & (segment_df['stance_time_balance'] < 100)
            if np.sum(valid_segment) >= 5:
                segment_balance = segment_df[valid_segment]['stance_time_balance'].values
                segment_means.append(np.mean(segment_balance))
                segment_names.append(segment_name)
        
        if segment_means:
            fig.add_trace(
                go.Bar(x=segment_names, y=segment_means, name='Segment Balance'),
                row=2, col=2
            )
        
        fig.update_layout(height=800, title_text="Interactive Stance Time Balance Analysis")
        
        # Save interactive visualization
        interactive_path = self.results_dir / 'stance_time_balance_interactive.html'
        fig.write_html(str(interactive_path))
        
        print(f"  üìä Interactive visualization saved: {interactive_path}")
    
    def save_results(self, results):
        """Save analysis results to JSON"""
        output_file = self.results_dir / 'stance_time_balance_results.json'
        
        # Convert numpy types for JSON serialization
        def convert_numpy_types(obj):
            if isinstance(obj, np.integer):
                return int(obj)
            elif isinstance(obj, np.floating):
                return float(obj)
            elif isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, dict):
                return {key: convert_numpy_types(value) for key, value in obj.items()}
            elif isinstance(obj, list):
                return [convert_numpy_types(item) for item in obj]
            else:
                return obj
        
        results_json = convert_numpy_types(results)
        
        with open(output_file, 'w') as f:
            json.dump(results_json, f, indent=2)
        
        print(f"  üíæ Results saved: {output_file}")
    
    def run_comprehensive_analysis(self):
        """Run complete stance time balance analysis"""
        print("\n" + "="*60)
        print("‚öñÔ∏è‚ö° COMPREHENSIVE STANCE TIME BALANCE ANALYSIS ‚ö°‚öñÔ∏è")
        print("="*60)
        print("Analyzing bilateral oscillatory coupling - left/right coordination!")
        print("="*60)
        
        # Load data
        if not self.load_track_data():
            return None
        
        # Run all experiments
        results = {}
        
        experiments = [
            ('bilateral_stability', self.analyze_bilateral_balance_stability),
            ('phase_coupling', self.analyze_bilateral_phase_coupling),
            ('terrain_adaptation', self.analyze_terrain_balance_adaptation),
        ]
        
        successful_experiments = 0
        
        for experiment_name, experiment_func in experiments:
            try:
                result = experiment_func()
                results[experiment_name] = result
                
                if result.get('validation_success', False):
                    successful_experiments += 1
                    
            except Exception as e:
                print(f"‚ùå Error in {experiment_name}: {str(e)}")
                results[experiment_name] = {'error': str(e)}
        
        # Generate comprehensive summary
        comprehensive_summary = {
            'total_experiments': len(experiments),
            'successful_validations': successful_experiments,
            'validation_success_rate': successful_experiments / len(experiments),
            'balance_oscillatory_validation_success': successful_experiments >= 2,
            'theoretical_predictions_validated': self._count_validated_predictions(results),
            'data_points_analyzed': len(self.data) if self.data is not None else 0,
            'balance_range_analyzed': f"{self.balance_time_series.min():.1f} - {self.balance_time_series.max():.1f} %",
            'mean_asymmetry': abs(np.mean(self.balance_time_series) - 50.0),
            'timestamp': pd.Timestamp.now().isoformat()
        }
        
        results['comprehensive_summary'] = comprehensive_summary
        
        # Create visualizations
        self.create_comprehensive_visualizations(results)
        
        # Save results
        self.save_results(results)
        
        # Print final summary
        print("\n" + "="*60)
        print("üìä STANCE TIME BALANCE ANALYSIS SUMMARY")
        print("="*60)
        print(f"Experiments Run: {len(experiments)}")
        print(f"Successful Validations: {successful_experiments}")
        print(f"Success Rate: {comprehensive_summary['validation_success_rate']*100:.1f}%")
        print(f"Framework Validated: {comprehensive_summary['balance_oscillatory_validation_success']}")
        print(f"Balance Range: {comprehensive_summary['balance_range_analyzed']}")
        print(f"Mean Asymmetry: {comprehensive_summary['mean_asymmetry']:.1f}%")
        print("="*60)
        
        if comprehensive_summary['balance_oscillatory_validation_success']:
            print("\nüéâ BILATERAL BALANCE VALIDATION SUCCESS! üéâ")
            print("Left/right oscillatory coupling theories validated with real data!")
            print("First framework to analyze bilateral biomechanical coupling!")
        else:
            print(f"\n‚ö†Ô∏è Partial validation achieved - more analysis needed")
        
        return results
    
    def _count_validated_predictions(self, results):
        """Count total validated theoretical predictions"""
        total_predictions = 0
        
        for experiment_result in results.values():
            if isinstance(experiment_result, dict) and 'theoretical_validation' in experiment_result:
                theoretical_val = experiment_result['theoretical_validation']
                if isinstance(theoretical_val, dict):
                    total_predictions += sum(1 for pred in theoretical_val.values() if pred)
        
        return total_predictions


def main():
    """Main function to run stance time balance analysis"""
    print("Starting Stance Time Balance Analysis...")
    
    analyzer = StanceTimeBalanceAnalyzer()
    results = analyzer.run_comprehensive_analysis()
    
    if results:
        print(f"\nüéØ ANALYSIS COMPLETE!")
        print(f"Results saved in: {analyzer.results_dir}")
        
        if results.get('comprehensive_summary', {}).get('balance_oscillatory_validation_success', False):
            print(f"\nüèÜ BREAKTHROUGH: BILATERAL COUPLING VALIDATES THEORIES! üèÜ")
            print(f"First framework to validate left/right oscillatory coupling!")
    else:
        print(f"\n‚ùå Analysis could not be completed")


if __name__ == "__main__":
    main()
